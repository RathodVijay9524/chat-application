spring.application.name=chat-app
server.port=8080

# CORS Configuration
spring.web.cors.allowed-origins=http://localhost:3000,http://localhost:3001
spring.web.cors.allowed-methods=GET,POST,PUT,DELETE,OPTIONS
spring.web.cors.allowed-headers=*
spring.web.cors.allow-credentials=true

# OpenAI Configuration
spring.ai.openai.api-key=${OPENAI_API_KEY:}
spring.ai.openai.chat.options.model=gpt-3.5-turbo
spring.ai.openai.chat.options.temperature=0.7
spring.ai.openai.chat.options.max-tokens=1000

# Anthropic Claude Configuration
spring.ai.anthropic.api-key=${CLAUDAI_API_KEY:}
spring.ai.anthropic.chat.options.model=claude-3-haiku-20240307
spring.ai.anthropic.chat.options.temperature=0.7
spring.ai.anthropic.chat.options.max-tokens=1000

# OpenRouter AI Configuration (using OpenAI-compatible interface) mistral-small-3.1-24b-instruct:free
spring.ai.openrouter.api-key=${OPENROUTER_API_KEY:}
spring.ai.openrouter.base-url=https://openrouter.ai/api/v1
spring.ai.openrouter.chat.options.model=openai/gpt-3.5-turbo
spring.ai.openrouter.chat.options.temperature=0.7
spring.ai.openrouter.chat.options.max-tokens=1000

# Google Gemini Configuration (Custom Implementation)
gemini.api-key=${GEMINI_API_KEY:}
gemini.base-url=https://generativelanguage.googleapis.com/v1beta/openai

# Ollama Configuration
spring.ai.ollama.base-url=http://localhost:11434
spring.ai.ollama.chat.options.model=qwen2.5-coder:1.5b
spring.ai.ollama.chat.options.temperature=0.7

# Hugging Face Configuration
spring.ai.huggingface.chat.api-key=${HUGGINGFACE_API_KEY:}
spring.ai.huggingface.chat.url=https://api-inference.huggingface.co/models
spring.ai.huggingface.chat.options.temperature=0.7
spring.ai.huggingface.chat.options.max-tokens=1000
spring.ai.huggingface.chat.options.return-full-text=false

# Groq Configuration (Custom Implementation)
groq.api-key=${GROQ_API_KEY:}
groq.base-url=https://api.groq.com/openai/v1


# MCP Server Configuration
spring.ai.mcp.client.enabled=true
spring.ai.mcp.client.toolcallback.enabled=true
spring.ai.mcp.client.sse.connections.my-mcp-server.url=http://localhost:8081

# Register your Python MCP server over STDIO
spring.ai.mcp.client.stdio.connections.coding-assistant.command=python
spring.ai.mcp.client.stdio.connections.coding-assistant.args[0]=E:/ai_projects/MCP_apps/coding_assistant_mcp/coding_assistant_mcp.py


# RAG Configuration - Vector Store (Disabled - requires PostgreSQL)
# spring.ai.vectorstore.pgvector.index-type=HNSW
# spring.ai.vectorstore.pgvector.distance-type=COSINE_DISTANCE
# spring.ai.vectorstore.pgvector.dimensions=1536
# spring.ai.vectorstore.pgvector.url=jdbc:postgresql://localhost:5432/vectordb
# spring.ai.vectorstore.pgvector.username=postgres
# spring.ai.vectorstore.pgvector.password=password

# RAG Configuration - Embeddings (Disabled - requires PostgreSQL)
# spring.ai.openai.embedding.options.model=text-embedding-3-small
# spring.ai.openai.embedding.options.dimensions=1536


# Logging
logging.level.com.vijay=DEBUG
logging.level.org.springframework.ai=DEBUG

